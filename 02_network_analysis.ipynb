{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22209a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5405076377351656\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import math\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reddit = praw.Reddit(\"project\")\n",
    "commentFrame = pd.read_pickle(\"comments.pkl\")\n",
    "\n",
    "variance = commentFrame[\"sentimentLabel\"].var()\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6113fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_nodes_from(commentFrame[\"original post\"].unique(), bipartite = 0)\n",
    "graph.add_nodes_from(commentFrame[\"author\"].unique(), bipartite = 1)#average weighted upvotes, average sentiment\n",
    "\n",
    "author_upvotes = commentFrame.groupby(\"author\")[\"upvoteScale\"].mean().to_dict()\n",
    "\n",
    "author_sentiment = (\n",
    "    commentFrame.groupby(\"author\")[\"AverageUserSentiment\"].first().to_dict()\n",
    ")\n",
    "\n",
    "nx.set_node_attributes(graph, author_upvotes, \"avg_upvotes\")\n",
    "nx.set_node_attributes(graph, author_sentiment, \"avg_sentiment\")\n",
    "edges = zip(\n",
    "    commentFrame[\"author\"],\n",
    "    commentFrame[\"original post\"],\n",
    "    commentFrame[\"body\"],\n",
    "    commentFrame[\"upvoteScale\"]\n",
    ")\n",
    "#attributes arnt carried over\n",
    "graph.add_edges_from((a, b, {\"body\": c, \"upvotes\": d}) for a, b, c, d in edges)\n",
    "\n",
    "uniqueUsers = [node for node, dic in graph.nodes(data = True) if dic[\"bipartite\"] == 1]\n",
    "biGraph = bipartite.weighted_projected_graph(graph, uniqueUsers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c6eb269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4441\n",
      "458234\n",
      "isolates:0\n",
      "nodes:608\n",
      "edges:2344\n"
     ]
    }
   ],
   "source": [
    "print(biGraph.number_of_nodes())\n",
    "print(biGraph.number_of_edges())\n",
    "userGraph = biGraph.copy()\n",
    "edges_to_remove = [(u,v) for u, v, d in biGraph.edges(data = True) if d[\"weight\"] <= 1]\n",
    "userGraph.remove_edges_from(edges_to_remove)\n",
    "\n",
    "isolates = list(nx.isolates(userGraph))\n",
    "userGraph.remove_nodes_from(isolates)\n",
    "print(f\"isolates:{len(list(nx.isolates(userGraph)))}\")\n",
    "print(f\"nodes:{userGraph.number_of_nodes()}\")\n",
    "print(f\"edges:{userGraph.number_of_edges()}\")\n",
    "#userGraph = biGraph.copy() #CHANGE THIS LINE BACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb86656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogenity: 0.7844978458279479\n",
      "assortivity: -0.008620384616553295\n",
      "fullgraph stats\n",
      "nodes: 608\n",
      "isolates: 0\n",
      "edges: 2344\n",
      "G_Giant stats\n",
      "567\n",
      "2320\n"
     ]
    }
   ],
   "source": [
    "fullGraph = nx.Graph()\n",
    "fullGraph.add_nodes_from(userGraph)\n",
    "\n",
    "for u, v, data in userGraph.edges(data = True):\n",
    "    raw_weight = data.get(\"weight\", 1)\n",
    "\n",
    "    deg_u = userGraph.degree(u, weight = \"weight\")\n",
    "    deg_v = userGraph.degree(v, weight  = \"weight\")\n",
    "    normalized = raw_weight / math.sqrt(deg_u * deg_v) if deg_u > 0 and deg_v > 0 else 0\n",
    "    fullGraph.add_edge(u, v, weight = normalized)\n",
    "user_sentiment = commentFrame.groupby(\"author\")['sentimentLabel'].mean().to_dict()\n",
    "nx.set_node_attributes(fullGraph, user_sentiment, \"sentiment\")\n",
    "\n",
    "sentiments = [d['sentiment'] for _, d in fullGraph.nodes(data=True) if \"sentiment\" in d]\n",
    "homogenity = 1 - np.var(sentiments)\n",
    "print(f\"homogenity: {homogenity}\")\n",
    "assort = nx.attribute_assortativity_coefficient(fullGraph, \"sentiment\")\n",
    "print(f\"assortivity: {assort}\")\n",
    "\n",
    "\n",
    "\n",
    "isolates = list(nx.isolates(fullGraph))\n",
    "print(\"fullgraph stats\")\n",
    "print(f\"nodes: {fullGraph.number_of_nodes()}\")\n",
    "print(f\"isolates: {len(isolates)}\")\n",
    "print(f\"edges: {userGraph.number_of_edges()}\")\n",
    "\n",
    "components = nx.connected_components(fullGraph)\n",
    "giant_component = max(components, key = len)\n",
    "G_Giant = fullGraph.subgraph(giant_component)\n",
    "print(\"G_Giant stats\")\n",
    "print(G_Giant.number_of_nodes())\n",
    "print(G_Giant.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80a4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullgraph = G_Giant.copy()\n",
    "#with open(\"user_graph.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(fullgraph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0f5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num communities: 10\n",
      "Community 0: [0, 4, 12, 19, 23, 58, 112, 118, 126, 129, 130, 134, 139, 140, 141, 142, 152, 205, 207, 210, 211, 214, 216, 219, 220, 224, 226, 227, 232, 238, 258, 263, 266, 268, 271, 274, 287, 316, 343, 344, 345, 348, 351, 355, 356, 357, 358, 433, 434, 435, 448, 449, 451, 453, 457, 458, 475, 478, 480, 484, 485, 489, 500, 501, 539, 542, 545, 547, 548, 560, 561]\n",
      "Community 1: [20, 27, 29, 32, 54, 75, 84, 86, 88, 92, 158, 161, 184, 195, 370, 372, 386, 413, 415, 416, 417, 419, 424, 425, 428, 430, 431, 432, 437, 438, 440, 444, 445, 447, 455, 456, 468, 482, 487, 493, 494, 495, 496, 497, 498, 499, 504, 505, 506, 507, 508, 509, 512, 513, 515, 518, 519, 521, 523, 524, 525, 526, 527, 536, 537, 538, 540, 546, 556, 565]\n",
      "Community 2: [3, 7, 9, 10, 11, 17, 28, 143, 144, 146, 149, 150, 153, 154, 155, 156, 159, 169, 171, 172, 173, 178, 183, 186, 187, 189, 191, 192, 194, 228, 252, 253, 257, 265, 267, 273, 275, 279, 281, 288, 289, 296, 297, 298, 304, 305, 306, 310, 312, 313, 314, 317, 318, 320, 321, 322, 324, 326, 414, 427, 529, 530, 531, 532, 533, 552, 566]\n",
      "Community 3: [1, 49, 50, 52, 53, 151, 157, 176, 177, 190, 233, 237, 245, 249, 251, 261, 286, 329, 330, 331, 333, 335, 349, 352, 353, 366, 367, 368, 375, 377, 379, 380, 385, 387, 388, 392, 393, 394, 395, 397, 399, 402, 405, 406, 420, 436, 464, 465, 466, 470, 472, 476, 502, 514, 535, 541, 543, 544, 550, 553, 555, 558, 559]\n",
      "Community 4: [5, 30, 33, 34, 36, 37, 38, 39, 41, 45, 47, 62, 78, 99, 125, 196, 197, 198, 201, 208, 209, 217, 223, 225, 229, 230, 231, 235, 236, 240, 241, 242, 244, 283, 328, 332, 334, 408, 409, 410, 411, 412, 421, 423, 426, 439, 441, 442, 446, 467, 469, 473, 474, 481, 503, 511, 516, 517, 522, 549, 557]\n",
      "Community 5: [8, 13, 15, 21, 24, 26, 51, 55, 57, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 79, 80, 81, 83, 85, 87, 90, 94, 96, 246, 247, 248, 250, 254, 255, 256, 259, 260, 262, 269, 270, 272, 276, 277, 278, 280, 282, 323, 363, 422, 429, 443, 454, 490, 510, 551, 554]\n",
      "Community 6: [35, 43, 46, 48, 56, 72, 82, 91, 93, 98, 111, 122, 136, 179, 181, 188, 199, 200, 202, 203, 204, 206, 212, 213, 215, 264, 284, 291, 292, 336, 337, 338, 339, 359, 360, 361, 362, 364, 365, 369, 373, 374, 376, 378, 381, 382, 383, 384, 389, 390, 398, 400, 401, 403, 407, 418, 452, 534]\n",
      "Community 7: [44, 97, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124, 127, 128, 131, 132, 133, 135, 137, 138, 145, 148, 180, 185, 193, 285, 290, 299, 307, 309, 319, 491, 492, 562, 563, 564]\n",
      "Community 8: [40, 110, 147, 160, 165, 167, 168, 170, 174, 175, 182, 221, 222, 234, 239, 243, 293, 294, 295, 300, 301, 302, 303, 308, 311, 315, 325, 327, 340, 341, 342, 346, 347, 350, 354, 391, 396, 404, 483, 486, 520, 528]\n",
      "Community 9: [2, 6, 14, 16, 18, 22, 25, 31, 42, 64, 73, 89, 95, 162, 163, 164, 166, 218, 371, 450, 459, 460, 461, 462, 463, 471, 477, 479, 488]\n",
      "Modularity: 0.5660155321046373\n"
     ]
    }
   ],
   "source": [
    "fullgraph = G_Giant.copy()\n",
    "nodeList = list(fullgraph.nodes())\n",
    "edges = [(nodeList.index(u), nodeList.index(v)) for u, v in fullgraph.edges()]\n",
    "\n",
    "g = ig.Graph(edges = edges, directed = False)\n",
    "\n",
    "if nx.get_edge_attributes(fullgraph, \"weight\"):\n",
    "    g.es[\"weight\"] = [fullgraph[u][v].get(\"weight\", 1.0) for u, v in fullgraph.edges()]\n",
    "\n",
    "partition = leidenalg.find_partition(g, leidenalg.ModularityVertexPartition)\n",
    "\n",
    "# Number of communities\n",
    "print(\"Num communities:\", len(partition))\n",
    "\n",
    "# List nodes per community\n",
    "for i, comm in enumerate(partition):\n",
    "    print(f\"Community {i}: {comm}\")\n",
    "\n",
    "# Modularity score\n",
    "print(\"Modularity:\", partition.quality())\n",
    "\n",
    "with open(\"user_graph.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fullGraph, f)\n",
    "#nx.draw(fullGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adaa711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: 608, edges: 2344, density: 0.012703, percent of nodes left after pruning: 13.69%\n",
      "components: 20, giant component size: 567, avg degree: 7.71\n",
      "top degrees: [184, 94, 87, 72, 72, 61, 55, 54, 49, 45]\n"
     ]
    }
   ],
   "source": [
    "G = fullGraph.copy()\n",
    "n = G.number_of_nodes()\n",
    "percent = n/biGraph.number_of_nodes() * 100\n",
    "m = G.number_of_edges()\n",
    "density = nx.density(G)\n",
    "components = list(nx.connected_components(G)) if not G.is_directed() else list(nx.weakly_connected_components(G))\n",
    "num_components = len(components)\n",
    "giant_size = max(len(c) for c in components) if components else 0\n",
    "avg_degree = sum(dict(G.degree()).values())/n\n",
    "\n",
    "print(f\"nodes: {n}, edges: {m}, density: {density:.6f}, percent of nodes left after pruning: {percent:.2f}%\")\n",
    "print(f\"components: {num_components}, giant component size: {giant_size}, avg degree: {avg_degree:.2f}\")\n",
    "# degree distribution quick view\n",
    "deg_seq = sorted([d for _, d in G.degree()], reverse=True)\n",
    "print(\"top degrees:\", deg_seq[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
